# Entropy

In cryptography, "entropy" is a fancy word for "randomness". The more entropy a key has, the harder it will be to brute force it.

For example, a 256-bit key has `2^256` bits of entropy.

## Is It Hard to Get Enough Entropy?

As it turns out, it's really hard to generate random numbers with computers. Computers are good at doing exactly what we tell them to. Think about it, if you didn't have access to a library like `rand.Reader()`, how would you get a random number?

As it turns out, all "random" libraries go down to the operating system to get their sources of randomness. For example, the Linux kernel uses things like the keyboard and mouse inputs, and even information about the static electricity in your machine to seed their secure random number generators.

## Getting Secure Random Numbers

When we need "cryptographically secure" random numbers, we need to use a secure (unguessable to an attacker) source. In Go, the crypto/rand library takes care of this for us by making the proper system calls to get sufficient entropy from the OS.

## Pseudorandom Numbers

Sometimes we need "pseudorandom" numbers, and in that case, we can use the math/rand library in Go. "Pseudorandom" numbers are generated by a deterministic algorithm. They appear random, but there is a pattern to how they're made, which makes them great for testing.

The system clock of a computer is often used to seed the entropy for pseudorandom numbers. If you ask for a pseudorandom number twice at exactly the same millisecond, you will get the same number each time.

